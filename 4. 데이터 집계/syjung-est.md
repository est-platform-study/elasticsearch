## 데이터 집계
 - 집계는 지표와 버킷으로 나눌 수 있다.
    - 지표집계 : 문서 그룹의 통계 분석
    - 버킷집계 : 여러 개의 버킷에 일치하는 문서를 나눈 다음 각 버킷의 문서의 수를 돌려준다.
### 집계 내부 이해하기
 - "aggregations", "aggs"
 - 집계는 질의 결과에 실행된다. 질의에 일치하지 않는 문서는 처리되지 않는다.
~~~
 "query": {
   "match": {
     "location": "Denver"
   }
 },
 "aggregations": {
   "top_tags": { <- 집계명
     "terms": {
       "field": "tags.verbatim"
     }
   }
 }
~~~

### filter, post_filter 와 집계
~~~
"query": {
  "filtered": {
    "filter": {
      ...
    }
  }
}
~~~
~~~
"post_filter": {
  ...
}
~~~
[filter, post_filter_290p 그림 7.3, 7.4]
 - filter를 감싼 filtered질의가 먼저 실행되고 집계와 결과를 제한한다.
 - post_filter는 질의 이후에 실행되며 집계에는 영향을 미치지 않음.
 - 전체에 요청을 하는 건 filtered 질의와 같이 먼저 결과를 필터하는 것보다 일반적으로 느리다.

### 통계
 - 질의에 일치하는 모든 문서의 값을 찾아 계산하여 매번 100% 정확하다.
 - aggregations 를 이용하여 avg, min, max, value_count 등을 통계낼 수 있다.
 - extended_stats
    - 제곱의 합, 분산, 표준편차 등의 정보를 얻을 수 있다.
    ~~~
    "aggregations": {
      "attendees_extends_stats": {
        "extended_stats": {
          "script" : {...}
        }
      }
    }
    ~~~

### 근사치 통계
 - 문서에서 값을 높은 정확성으로(100% 아님) 찾아 계산한다. 정확성은 낮지만 적은 메모리를 사용하며 더 빠르다.

#### 백분위
 - 80번째, 99번째 백분위 값 구하기
~~~
"percentiles": {
  "script": {...},
  "percents": [80, 99]
}
~~~
 - compression 파라미터를 이용하여 메모리 사용량과 정확도를 조절할 수 있다.

#### 카디널리티  
 ~~~
  집합원의 갯수
  중복도가 낮으면 카디널리티가 높다고 표현한다.
  중복도가 높으면 카디널리티가 낮다고 표현한다.

  id	name	location
  0	lee	seoul
  1	park	pusan
  2	choi	seoul
  3	park	seoul
  4	kim	seoul
  5	bae	incheon
  6	ahn	seoul
  7	lee	seoul
  8	lee	seoul
  9	kim	seoul

  - id의 경우 전체 10건의 로우에 대해 중복된 값이 없으므로 카디널리티가 높다.
  - name의 경우 distinct 값이 6건이므로 (lee, park, choi, kim, bae, ahm) id컬럼보다는 카디널리티가 낮다
  - location의 경우 distinct 값이 3건밖에 없으므로 (seoul, pusan, incheon) 카디널리티가 제일 낮다
 ~~~
 - terms 집계를 이용하여 카디널리티값을 구할 수 있지만 아래와같은 차이가 있음.
    - 메모리 : 유일한 단어를 계산하기 위해 메모리에 모든 단어가 적재되어야한다.
    - CPU : 결과는 정렬되어 보여야한다. 기본적으로 순서는 각 용어가 발생한 횟수로 정렬된다.
    - 네트워크 : 각 샤드에서 유일한 단어로 정렬된 큰 배열이 사용자의 요청을 받은 노드로 전송되어야한다. 그리고 전달받은 노드는 사용자에게 값을 반환하기 위하여 전달받은 큰 배열을 하나의 배열로 합치는 작업을 해야한다.
 - HyperLogLog++ 알고리즘으로 동작한다.
    - 해시값을 바탕으로 근사값을 구하는 알고리즘으로, 메모리에 해시값을 한번만 적재하기때문에 얼마나 많은 단어를 검사하는지 상관없이 메모리 사용량이 일정함.
 - 메모리 사용량이 일정하다면 얼마나 큰것까지 될까?
    - precision_threshold 파라미터를통해 설정할 수 있다.
    - threshold 가 높으면 더 정확한 결과를 얻을 수 있지만 더 많은 메모리를 사용한다.
    - 만약 직접 카디널리티 집계를 실행하다면 precision_threshold*8byte 만큼의 메모리를 각 샤드에서 질의를 동작시키기 위해 사용한다.

### multi-bucket 집계
[multi-bucket_299p 표7.1]
 - 각 태그에 일치하는 문서의 그룹을 버킷에 넣은 후 집계.
#### 텀즈집계
 - 문서에서 각 단어의 빈도를 계산하려고 할때 사용한다.
 - 분석된 필드에서 가장 많이 사용된 단어를 뽑아낼 때 사용할 수 있다.
 - 많은 문서를 가지고 있거나 문서에 많은 단어를 포함하고 있다면 모든 필드가 메모리에 적제될 수 있도록 넉넉한 메모리가 있어야한다.
 - 블로그에서 사용자들이 자주 접근하는 글을 찾거나 인기 있는 태그를 찾을때 유용
 [텀즈집계_301p 그림7.5]
 [텀즈집계_304p 그림7.7, 7.8]

#### 범위집계
 - 버킷을 생성한 후 어떤 숫자, 날짜 또는 IP 주소 범위를 버킷에 나누는 방법이다.
 - 대부분 문자열과 함께 사용되지만 숫자형 값에도 동작한다.
 - 온라인 상점에서 어떤 물건에 대하여 검색한다고 할 때, 가장 인기있는 가격 범위를 알 수 있다.
 - 사용자의 나이가 18~39세 사이인지, 40~60세 사이인지 아니면 다른 범위인지

#### 히스토그램 집계
 - 숫자형 or 날짜형 중 하나를 사용하며 범위 집계와 유사하다.
 - 고정된 간격을 정의하면 elasticsearch는 간격에 맞춰 버킷을 생성한다.
 - 사용자가 어떤 값을 볼지 모르는 경우에 유용하다.
 - 매달 얼마나 많은 이벤트가 발생하는지 도표로 보여줄 수 있다.

### 중첩집계
 - 중첩, 역 중첩, 자식 집계는 문서의 관계에 걸쳐서 집계를 실행한다.
 [중첩집계_317p 그림7.10]

### Geo 거리, Geo hash grid 집계
 - 지리정보를 기반으로 버킷을 생성한다.

### 기타~
 - 스크립트는 질의에 사용할 떄 유연하지만, 성능과 보안 관점에서 주의사항을 알고 있어야한다.
 - 대부분의 배포된 elasticsearch에서 사용자는 query string을 명시하고 서버 어플리케이션이 질의를 생성한다. 그러나 사용자가 스크립트를 포함한 어떤 종류의 질의든 사용할 수 있도록 한다면, 악용하여 악성코드를 실행할 수 있다.
 - 그래서 인라인 스크립트를 실행하는(dynamic scripting) 것이 비활성화 되어있을것이며, 설정값으로 활성화 시킬 수 있다.
